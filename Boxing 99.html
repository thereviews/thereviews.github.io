<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>AI Boxing Coach — Selfie (Portrait)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />

  <style>
    body { 
      margin:0; padding:0;
      font-family:system-ui, Arial;
      background:#0a0a0a; color:#eee;
      display:flex; flex-direction:column;
      align-items:center; 
      overflow:hidden;
    }
    #wrap {
      position:relative;
      width:100vw; 
      max-width:450px;
      height:75vh;
      background:#000;
      border-radius:10px;
      overflow:hidden;
    }
    video, canvas {
      position:absolute;
      top:0; left:0;
      width:100%; height:100%;
      object-fit:cover;
    }
    #hud {
      position:absolute;
      top:0; left:0;
      width:100%;
      display:flex;
      flex-wrap:wrap;
      justify-content:space-between;
      background:rgba(0,0,0,0.35);
      padding:6px 10px;
      font-size:12px;
      box-sizing:border-box;
    }
    .stat { padding:2px 4px; color:#0ff; font-weight:600; }
    #controls {
      margin-top:10px;
      display:flex; gap:6px;
      flex-wrap:wrap;
      justify-content:center;
    }
    button {
      padding:8px 12px; border-radius:8px;
      border:0; background:#007bff;
      color:#fff; font-weight:600;
    }
  </style>
</head>
<body>

  <h3 style="margin:6px 0;">AI Boxing Coach — Selfie (Portrait)</h3>

  <div id="wrap">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>

    <div id="hud">
      <div class="stat">Jabs: <span id="jabs">0</span></div>
      <div class="stat">Crosses: <span id="crosses">0</span></div>
      <div class="stat">Status: <span id="status">idle</span></div>
    </div>
  </div>

  <div id="controls">
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <button id="resetBtn">Reset</button>
  </div>

  <!-- Correct TF Runtime + Backend + Pose Detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@3.21.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.7"></script>

  <script>
  (async ()=> {

    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const jabsEl = document.getElementById('jabs');
    const crossesEl = document.getElementById('crosses');
    const statusEl = document.getElementById('status');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const resetBtn = document.getElementById('resetBtn');

    let detector = null;
    let running = false;
    let rafId = null;
    let jabs = 0, crosses = 0;
    let prevLeftDist = null, prevRightDist = null;
    let lastLeftPunchAt = 0, lastRightPunchAt = 0;
    const punchCooldown = 300;
    const speedThreshold = 0.015;

    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    function beep() {
      const o = audioCtx.createOscillator();
      const g = audioCtx.createGain();
      o.frequency.value = 880;
      g.gain.value = 0.001;
      o.connect(g); g.connect(audioCtx.destination);
      o.start();
      g.gain.exponentialRampToValueAtTime(0.00001, audioCtx.currentTime + 0.14);
      o.stop(audioCtx.currentTime + 0.15);
    }

    async function startCamera() {
      const constraints = { 
        audio:false, 
        video: { facingMode:{exact:"user"}, width:{ideal:1280}, height:{ideal:720} } 
      };
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;
      video.setAttribute("playsinline","true");
      video.style.transform = "scaleX(-1)";
      await new Promise(r => video.onloadedmetadata = r);
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;
    }

    async function loadDetector() {
      statusEl.textContent = 'loading model...';

      const model = poseDetection.SupportedModels.MoveNet;
      detector = await poseDetection.createDetector(model, {
        modelType: poseDetection.movenet.modelType.SINGLEPOSE_THUNDER,
        enableSmoothing: true,
        runtime: 'tfjs',
        modelUrl: 'https://tfhub.dev/google/tfjs-model/movenet/singlepose/thunder/4'
      });

      statusEl.textContent = 'model loaded';
    }

    function drawKeypoints(keypoints) {
      ctx.clearRect(0,0,overlay.width,overlay.height);
      ctx.fillStyle = 'rgba(0,200,255,0.9)';
      for (const kp of keypoints) {
        if (kp.score > 0.3) {
          ctx.beginPath();
          ctx.arc(kp.x * overlay.width, kp.y * overlay.height, 6, 0, Math.PI*2);
          ctx.fill();
        }
      }
    }

    function now() { return (new Date()).getTime(); }

    async function runFrame() {
      if (!running || !detector) return;

      const poses = await detector.estimatePoses(video, {flipHorizontal:true});
      if (poses && poses.length > 0) {
        const kp = poses[0].keypoints.reduce((m,k)=>{m[k.name]=k; return m;}, {});
        drawKeypoints(Object.values(kp));

        const LW = kp['left_wrist'], LS = kp['left_shoulder'];
        if (LW && LS && LW.score>0.3 && LS.score>0.3) {
          const distL = Math.hypot(LW.x-LS.x, LW.y-LS.y);
          if (prevLeftDist != null && distL - prevLeftDist > speedThreshold && now()-lastLeftPunchAt>punchCooldown) {
            jabs++; jabsEl.textContent = jabs; lastLeftPunchAt = now(); beep();
          }
          prevLeftDist = distL;
        } else prevLeftDist = null;

        const RW = kp['right_wrist'], RS = kp['right_shoulder'];
        if (RW && RS && RW.score>0.3 && RS.score>0.3) {
          const distR = Math.hypot(RW.x-RS.x, RW.y-RS.y);
          if (prevRightDist != null && distR - prevRightDist > speedThreshold && now()-lastRightPunchAt>punchCooldown) {
            crosses++; crossesEl.textContent = crosses; lastRightPunchAt = now(); beep();
          }
          prevRightDist = distR;
        } else prevRightDist = null;

      } else ctx.clearRect(0,0,overlay.width,overlay.height);

      rafId = requestAnimationFrame(runFrame);
    }

    startBtn.addEventListener('click', async ()=>{
      startBtn.disabled = true; stopBtn.disabled = false; resetBtn.disabled = false;
      statusEl.textContent = 'starting camera...';

      await startCamera();
      await tf.setBackend('webgl');
      await tf.ready();
      if (!detector) await loadDetector();

      running = true;
      statusEl.textContent = 'running';
      runFrame();
    });

    stopBtn.addEventListener('click', ()=>{
      running = false;
      startBtn.disabled = false; stopBtn.disabled = true;
      statusEl.textContent = 'stopped';
      if (rafId) cancelAnimationFrame(rafId);
      if (video.srcObject) video.srcObject.getTracks().forEach(t => t.stop());
    });

    resetBtn.addEventListener('click', ()=>{
      jabs = 0; crosses = 0;
      jabsEl.textContent = jabs; crossesEl.textContent = crosses;
      prevLeftDist = prevRightDist = null;
    });

  })();
  </script>

</body>
</html>
